--------------------------------------------------------------------------------
üìå Question 71 ‚≠ê‚≠ê‚≠ê
--------------------------------------------------------------------------------
You are developing an Azure App Service hosted ASP.NET Core web app to deliver video-on-demand streaming media. You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint. Customer videos are downloaded from the web app by using the following example URL: `http://www.contoso.com/content.mp4?quality=1`.

All media content must expire from the cache after one hour. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node.

You need to configure Azure CDN caching rules.

Which options should you use?

**Caching behavior**
1. Bypass cache
2. Override
3. Set if missing

**Cache expiration duration**
1. 1 second
2. 1 minute
3. 1 hour
4. 1 day

**Query string caching behavior**
1. Ignore query strings
2. Bypass caching for query strings
3. Cache every unique URL

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **Caching behavior:** Override
2. **Cache expiration duration:** 1 hour
3. **Query string caching behavior:** Cache every unique URL

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Caching behavior: Override**
The requirement states that "All media content must expire from the cache after one hour." To strictly enforce a specific cache duration regardless of what the origin server might send in its headers, you must use **Override**.
*   **Override:** Ignores the origin's cache duration and uses the provided CDN duration instead.
*   **Set if missing:** Only honors the CDN setting if the origin *doesn't* provide cache headers.
*   **Bypass cache:** Would not cache the content at all, failing the delivery requirement.

**2. Cache expiration duration: 1 hour**
This is a direct mapping from the requirement: "All media content must expire from the cache after one hour."

**3. Query string caching behavior: Cache every unique URL**
The scenario highlights that videos have varying quality determined by the query string: `http://www.contoso.com/content.mp4?quality=1`.
*   **Cache every unique URL:** This treats `content.mp4?quality=1` and `content.mp4?quality=2` as separate assets. This is necessary because the content (video quality) is structurally different based on that parameter.
*   **Ignore query strings:** This would cache the first request (e.g., quality=1) and serve it for all subsequent requests (even if someone requested quality=2), leading to incorrect content delivery.
*   **Bypass caching for query strings:** This would prevent the videos from being cached at the POP nodes, defeating the purpose of the CDN for these video assets.

**References:**
*   [Control Azure CDN caching behavior with caching rules](https://learn.microsoft.com/en-us/azure/cdn/cdn-caching-rules)
*   [Control Azure CDN caching behavior with query strings](https://learn.microsoft.com/en-us/azure/cdn/cdn-query-string)

--------------------------------------------------------------------------------
üìå Question 72
--------------------------------------------------------------------------------
You are using Azure Front Door Service.

You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size.

You need to determine the root cause for the issue.

To answer, select the appropriate options in the answer area.

**The file MIME type is supported by the service.**
1. Yes
2. No

**Edge nodes must be purged of all cache assets.**
1. Yes
2. No

**The compression type is supported.**
1. Yes
2. No

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **The file MIME type is supported by the service:** Yes
2. **Edge nodes must be purged of all cache assets:** No
3. **The compression type is supported:** Yes

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**Root Cause Analysis:**
The core issue is the **file size provided in the scenario (9 MB)**. Azure Front Door dynamic compression has a strict file size limit: files must be between 1 KB and 8 MB. Since the file is 9 MB, it exceeds the maximum size allowed for compression, regardless of the valid MIME type or compression settings.

**1. The file MIME type is supported by the service: Yes**
The standard list of default MIME types for Azure Front Door compression includes `application/xml`, `text/xml`, and `application/xhtml+xml`. Therefore, the file type itself is valid and supported.

**2. Edge nodes must be purged of all cache assets: No**
Purging the cache is a remediation step used when valid content is updated on the origin but the CDN is serving stale data. In this scenario, the lack of compression is not due to stale data but a configuration constraint (file size). Purging the cache will not force a 9 MB file to be compressed; it will simply re-fetch the uncompressed file.

**3. The compression type is supported: Yes**
Azure Front Door supports both **Gzip** and **Brotli** compression. Brotli is often the default or preferred compression method when supported by the client. The compression mechanism itself is supported, but it cannot run on this specific file due to the size limit.

**References:**
*   [Azure Front Door - Caching and Compression](https://learn.microsoft.com/en-us/azure/front-door/standard-premium/how-to-compression)
*   *Note: Documentation specifies the file size range for compression is 1 KB to 8 MB inclusive.*

--------------------------------------------------------------------------------
üìå Question 73
--------------------------------------------------------------------------------
You are developing an ASP.NET Core Web API web service. The web service uses Azure Application Insights for all telemetry and dependency tracking. The web service reads and writes data to a database other than Microsoft SQL Server.

You need to ensure that dependency tracking works for calls to the third-party database.

Which two dependency telemetry properties should you use? Each correct answer presents part of the solution.

A. Telemetry.Context.Cloud.RoleInstance
B. Telemetry.Id
C. Telemetry.Name
D. Telemetry.Context.Operation.Id
E. Telemetry.Context.Session.Id

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **D. Telemetry.Context.Operation.Id**
2. **B. Telemetry.Id**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Telemetry.Context.Operation.Id (Trace ID)**
This property is the **Root ID** or **Trace ID**. It is essential for **correlation**. To ensure the dependency call logic appears as part of the specific incoming HTTP request transaction in Application Insights, the dependency telemetry must share the same `Operation.Id` as the parent Request telemetry. This ties the entire tree of operations (Request -> Database Call) together.

**2. Telemetry.Id (Dependency/Span ID)**
This property represents the unique identifier for the specific dependency call (span) itself. In the telemetry data model, items are linked via IDs. The parent request refers to this dependency (conceptually), or if this dependency made further calls, this `Id` would become the `ParentId` for the next hop. Defining this is crucial for the telemetry item to be structurally valid and distinguishable within the transaction timeline.

**Why others are incorrect:**
*   **A. RoleInstance:** Defines the server/container (e.g., "server-01"). Useful for infrastructure mapping but not for tracking the logical flow of a database request.
*   **C. Name:** Defines the command name (e.g., "SELECT * FROM Users"). While vital for *readability* and *debugging*, the tracking *mechanism* (topology/linking) relies on IDs.
*   **E. Session.Id:** Identifies a user session (e.g., a browser session). It is not used for backend dependency correlation within a single HTTP request context.

**References:**
*   [Telemetry correlation in Application Insights](https://learn.microsoft.com/en-us/azure/azure-monitor/app/correlation)
*   [Application Insights API for custom events and metrics (TrackDependency)](https://learn.microsoft.com/en-us/azure/azure-monitor/app/api-custom-events-metrics#trackdependency)

--------------------------------------------------------------------------------
üìå Question
--------------------------------------------------------------------------------
You develop and deploy an Azure App Service web app. The app is deployed to multiple regions and uses Azure Traffic Manager. Application Insights is enabled for the app.

You need to analyze app uptime for each month.

Which two solutions will achieve the goal? Each correct answer presents a complete solution.

A. Azure Monitor logs
B. Application Insights alerts
C. Azure Monitor metrics
D. Application Insights web tests

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **A. Azure Monitor logs**
2. **C. Azure Monitor metrics**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Azure Monitor logs (A)**
Application Insights "Web Tests" (Availability tests) write their results to the **Azure Monitor Logs** (Log Analytics) workspace in a table called `availabilityResults`. You can use Kusto Query Language (KQL) to query this table, aggregating the success vs. failure results over specific time windows (e.g., `bin(timestamp, 30d)`) to calculate and report exact uptime percentages for each month.

**2. Azure Monitor metrics (C)**
Availability tests also emit data to **Azure Monitor metrics**. In the Metrics Explorer, you can select the "Availability" metric, set the time range to a month (or longer), and view the average availability percentage over that period. This provides a visual representation of uptime trends without needing to write queries.

**Why others are incorrect:**
*   **B. Application Insights alerts:** Alerts are designed for reactive real-time notifications (e.g., "Email me if uptime drops below 99%"). They are not designed for generating historical analysis reports of uptime "for each month."
*   **D. Application Insights web tests:** This is the *feature* you configure to generate the availability data (the probes that ping your site). While you must configure Web Tests to *get* the data, the specific tool used to *analyze* the stored data over a monthly period is either Logs or Metrics.

**References:**
*   [Alerts and queries on finding data in Log Analytics](https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability-overview#query-in-logs-analytics)
*   [Track availability of any web site](https://learn.microsoft.com/en-us/azure/azure-monitor/app/monitor-web-app-availability)
