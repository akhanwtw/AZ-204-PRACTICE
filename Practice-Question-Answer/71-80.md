--------------------------------------------------------------------------------
üìå Question 71 ‚≠ê‚≠ê‚≠ê
--------------------------------------------------------------------------------
You are developing an Azure App Service hosted ASP.NET Core web app to deliver video-on-demand streaming media. You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint. Customer videos are downloaded from the web app by using the following example URL: `http://www.contoso.com/content.mp4?quality=1`.

All media content must expire from the cache after one hour. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node.

You need to configure Azure CDN caching rules.

Which options should you use?

**Caching behavior**
1. Bypass cache
2. Override
3. Set if missing

**Cache expiration duration**
1. 1 second
2. 1 minute
3. 1 hour
4. 1 day

**Query string caching behavior**
1. Ignore query strings
2. Bypass caching for query strings
3. Cache every unique URL

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **Caching behavior:** Override
2. **Cache expiration duration:** 1 hour
3. **Query string caching behavior:** Cache every unique URL

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Caching behavior: Override**
The requirement states that "All media content must expire from the cache after one hour." To strictly enforce a specific cache duration regardless of what the origin server might send in its headers, you must use **Override**.
*   **Override:** Ignores the origin's cache duration and uses the provided CDN duration instead.
*   **Set if missing:** Only honors the CDN setting if the origin *doesn't* provide cache headers.
*   **Bypass cache:** Would not cache the content at all, failing the delivery requirement.

**2. Cache expiration duration: 1 hour**
This is a direct mapping from the requirement: "All media content must expire from the cache after one hour."

**3. Query string caching behavior: Cache every unique URL**
The scenario highlights that videos have varying quality determined by the query string: `http://www.contoso.com/content.mp4?quality=1`.
*   **Cache every unique URL:** This treats `content.mp4?quality=1` and `content.mp4?quality=2` as separate assets. This is necessary because the content (video quality) is structurally different based on that parameter.
*   **Ignore query strings:** This would cache the first request (e.g., quality=1) and serve it for all subsequent requests (even if someone requested quality=2), leading to incorrect content delivery.
*   **Bypass caching for query strings:** This would prevent the videos from being cached at the POP nodes, defeating the purpose of the CDN for these video assets.

**References:**
*   [Control Azure CDN caching behavior with caching rules](https://learn.microsoft.com/en-us/azure/cdn/cdn-caching-rules)
*   [Control Azure CDN caching behavior with query strings](https://learn.microsoft.com/en-us/azure/cdn/cdn-query-string)

--------------------------------------------------------------------------------
üìå Question 72
--------------------------------------------------------------------------------
You are using Azure Front Door Service.

You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size.

You need to determine the root cause for the issue.

To answer, select the appropriate options in the answer area.

**The file MIME type is supported by the service.**
1. Yes
2. No

**Edge nodes must be purged of all cache assets.**
1. Yes
2. No

**The compression type is supported.**
1. Yes
2. No

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **The file MIME type is supported by the service:** Yes
2. **Edge nodes must be purged of all cache assets:** No
3. **The compression type is supported:** Yes

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**Root Cause Analysis:**
The core issue is the **file size provided in the scenario (9 MB)**. Azure Front Door dynamic compression has a strict file size limit: files must be between 1 KB and 8 MB. Since the file is 9 MB, it exceeds the maximum size allowed for compression, regardless of the valid MIME type or compression settings.

**1. The file MIME type is supported by the service: Yes**
The standard list of default MIME types for Azure Front Door compression includes `application/xml`, `text/xml`, and `application/xhtml+xml`. Therefore, the file type itself is valid and supported.

**2. Edge nodes must be purged of all cache assets: No**
Purging the cache is a remediation step used when valid content is updated on the origin but the CDN is serving stale data. In this scenario, the lack of compression is not due to stale data but a configuration constraint (file size). Purging the cache will not force a 9 MB file to be compressed; it will simply re-fetch the uncompressed file.

**3. The compression type is supported: Yes**
Azure Front Door supports both **Gzip** and **Brotli** compression. Brotli is often the default or preferred compression method when supported by the client. The compression mechanism itself is supported, but it cannot run on this specific file due to the size limit.

**References:**
*   [Azure Front Door - Caching and Compression](https://learn.microsoft.com/en-us/azure/front-door/standard-premium/how-to-compression)
*   *Note: Documentation specifies the file size range for compression is 1 KB to 8 MB inclusive.*

--------------------------------------------------------------------------------
üìå Question 73
--------------------------------------------------------------------------------
You are developing an ASP.NET Core Web API web service. The web service uses Azure Application Insights for all telemetry and dependency tracking. The web service reads and writes data to a database other than Microsoft SQL Server.

You need to ensure that dependency tracking works for calls to the third-party database.

Which two dependency telemetry properties should you use? Each correct answer presents part of the solution.

A. Telemetry.Context.Cloud.RoleInstance
B. Telemetry.Id
C. Telemetry.Name
D. Telemetry.Context.Operation.Id
E. Telemetry.Context.Session.Id

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **D. Telemetry.Context.Operation.Id**
2. **B. Telemetry.Id**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Telemetry.Context.Operation.Id (Trace ID)**
This property is the **Root ID** or **Trace ID**. It is essential for **correlation**. To ensure the dependency call logic appears as part of the specific incoming HTTP request transaction in Application Insights, the dependency telemetry must share the same `Operation.Id` as the parent Request telemetry. This ties the entire tree of operations (Request -> Database Call) together.

**2. Telemetry.Id (Dependency/Span ID)**
This property represents the unique identifier for the specific dependency call (span) itself. In the telemetry data model, items are linked via IDs. The parent request refers to this dependency (conceptually), or if this dependency made further calls, this `Id` would become the `ParentId` for the next hop. Defining this is crucial for the telemetry item to be structurally valid and distinguishable within the transaction timeline.

**Why others are incorrect:**
*   **A. RoleInstance:** Defines the server/container (e.g., "server-01"). Useful for infrastructure mapping but not for tracking the logical flow of a database request.
*   **C. Name:** Defines the command name (e.g., "SELECT * FROM Users"). While vital for *readability* and *debugging*, the tracking *mechanism* (topology/linking) relies on IDs.
*   **E. Session.Id:** Identifies a user session (e.g., a browser session). It is not used for backend dependency correlation within a single HTTP request context.

**References:**
*   [Telemetry correlation in Application Insights](https://learn.microsoft.com/en-us/azure/azure-monitor/app/correlation)
*   [Application Insights API for custom events and metrics (TrackDependency)](https://learn.microsoft.com/en-us/azure/azure-monitor/app/api-custom-events-metrics#trackdependency)

--------------------------------------------------------------------------------
üìå Question 74
--------------------------------------------------------------------------------
You develop and deploy an Azure App Service web app. The app is deployed to multiple regions and uses Azure Traffic Manager. Application Insights is enabled for the app.

You need to analyze app uptime for each month.

Which two solutions will achieve the goal? Each correct answer presents a complete solution.

A. Azure Monitor logs
B. Application Insights alerts
C. Azure Monitor metrics
D. Application Insights web tests

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **A. Azure Monitor logs**
2. **C. Azure Monitor metrics**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Azure Monitor logs (A)**
Application Insights "Web Tests" (Availability tests) write their results to the **Azure Monitor Logs** (Log Analytics) workspace in a table called `availabilityResults`. You can use Kusto Query Language (KQL) to query this table, aggregating the success vs. failure results over specific time windows (e.g., `bin(timestamp, 30d)`) to calculate and report exact uptime percentages for each month.

**2. Azure Monitor metrics (C)**
Availability tests also emit data to **Azure Monitor metrics**. In the Metrics Explorer, you can select the "Availability" metric, set the time range to a month (or longer), and view the average availability percentage over that period. This provides a visual representation of uptime trends without needing to write queries.

**Why others are incorrect:**
*   **B. Application Insights alerts:** Alerts are designed for reactive real-time notifications (e.g., "Email me if uptime drops below 99%"). They are not designed for generating historical analysis reports of uptime "for each month."
*   **D. Application Insights web tests:** This is the *feature* you configure to generate the availability data (the probes that ping your site). While you must configure Web Tests to *get* the data, the specific tool used to *analyze* the stored data over a monthly period is either Logs or Metrics.

**References:**
*   [Alerts and queries on finding data in Log Analytics](https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability-overview#query-in-logs-analytics)
*   [Track availability of any web site](https://learn.microsoft.com/en-us/azure/azure-monitor/app/monitor-web-app-availability)

--------------------------------------------------------------------------------
üìå Question 75
--------------------------------------------------------------------------------
You develop an application. You plan to host the application on a set of virtual machines (VMs) in Azure.

You need to configure Azure Monitor to collect logs from the application.

Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.

**Actions Lists:**
*   Create a Log Analytics workspace.
*   Install agents on the VM and VM scale set to be monitored.
*   Send console logs.
*   Add a VMInsights solution.
*   Create an Application Insights resource.

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **Create a Log Analytics workspace.**
2. **Create an Application Insights resource.**
3. **Install agents on the VM and VM scale set to be monitored.**
4. **Send console logs.**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Create a Log Analytics workspace**
This is the foundational storage layer. Modern Application Insights resources are "workspace-based," meaning they store their data in a Log Analytics workspace. You must create this destination first.

**2. Create an Application Insights resource**
This is the logical entity in Azure that represents your application's monitoring configuration. It provides the connection string and specific telemetry views (failures, performance, map) for the application logic.

**3. Install agents on the VM and VM scale set to be monitored**
To collect telemetry from an application running on a VM without modifying the code (codeless/auto-instrumentation) or to act as a forwarder, you install the **Azure Monitor Application Insights Agent** (formerly Status Monitor v2 for .NET) or the Azure Monitor Agent. This agent sits on the server, hooks into the runtime/process, and offloads the data to Azure.

**4. Send console logs**
In the context of this specific exam question logic, this represents the application runtime configuration or validation step where the application generates the telemetry (logs) that the agent intercepts and forwards. (Note: "Add a VMInsights solution" is incorrect because VM Insights is specifically for infrastructure monitoring‚ÄîCPU, RAM, usage maps‚Äîof the *host* VM, not the *application* code logs).

**References:**
*   [Application Insights for Azure VMs and virtual machine scale sets](https://learn.microsoft.com/en-us/azure/azure-monitor/app/azure-vm-vmss-apps)
*   [Workspace-based Application Insights resources](https://learn.microsoft.com/en-us/azure/azure-monitor/app/create-workspace-resource)

--------------------------------------------------------------------------------
üìå Question 76
--------------------------------------------------------------------------------
You develop and deploy an Azure Logic App that calls an Azure Function app.

The Logic App must use **Azure Monitor logs** to record and store information about runtime data and events. The logs must be stored in the **Azure Blob storage account**.

You need to set up Azure Monitor logs and collect diagnostics data for the Azure Logic App.

Which three actions should you perform in sequence?

**Actions:**
*   Create action groups and alert rules.
*   Create a Log Analytics workspace.
*   Install the Logic Apps Management solution.
*   Add a diagnostic setting to the Azure Function App.
*   Create an Azure storage account.
*   Add a diagnostic setting to the Azure Logic App.

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **Create a Log Analytics workspace.**
2. **Install the Logic Apps Management solution.**
3. **Add a diagnostic setting to the Azure Logic App.**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Create a Log Analytics workspace**
The requirement explicitly states the Logic App must use **Azure Monitor logs**. In Azure terminology, "Azure Monitor logs" is synonymous with the **Log Analytics** service. You must create a workspace to serve as the ingestion point and query engine for this telemetry data.

**2. Install the Logic Apps Management solution**
To effectively use Azure Monitor logs with Logic Apps (to see run status, specific trigger details, and input/output data in a monitoring dashboard), you must enable the **Logic Apps Management solution** on your Log Analytics workspace. This installs the necessary schemas and view definitions.
*(Note: While newer versions of Logic Apps have integrated insights, the standard "Azure Monitor Logs" exam pattern involves this specific Solution installation).*

**3. Add a diagnostic setting to the Azure Logic App**
Once the destination (Workspace) and the schema (Solution) are ready, you must configure the Logic App itself to emit the logs. This is done by adding a **Diagnostic Setting**. Inside this setting configuration, you select the specific metric/log categories to collect and choose the destinations:
*   **Send to Log Analytics workspace** (satisfies "use Azure Monitor logs").
*   **Archive to a storage account** (satisfies "stored in the Azure Blob storage account").
*   *(Note: The prompt implies using the existing storage account mentioned in the context, or simply enabling the archival option in this step).*

**Why others are incorrect/not in sequence:**
*   *Create an Azure storage account:* The scenario mentions the Function App already uses a storage account, implying one exists that can be targeted. The critical interpretation of "Azure Monitor logs" points to the Workspace/Solution setup as the primary infrastructure task.
*   *Add a diagnostic setting to the Azure Function App:* The goal is to monitor the **Logic App**, not the Function App.
*   *Create action groups:* This is for alerting (sending emails/SMS), not for the collection and storage of logs.

**References:**
*   [Set up Azure Monitor logs and collect diagnostics data for Azure Logic Apps](https://learn.microsoft.com/en-us/azure/logic-apps/monitor-logic-apps-log-analytics)

--------------------------------------------------------------------------------
üìå Question 77
--------------------------------------------------------------------------------
You are developing an application to retrieve user profile information. The application will use the Microsoft Graph SDK.
The app must retrieve user profile information by using a Microsoft Graph API call.
You need to call the Microsoft Graph API from the application.

In which order should you perform the actions? To answer, move all actions from the list of actions to the answer area and arrange them in the correct order.

**Actions:**
*   Create an authentication provider.
*   Create a new instance of the GraphServiceClient.
*   Invoke the request to the Microsoft Graph API.
*   Register the application with the Microsoft identity platform.
*   Build a client by using the client app ID.

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **Register the application with the Microsoft identity platform.**
2. **Build a client by using the client app ID.**
3. **Create an authentication provider.**
4. **Create a new instance of the GraphServiceClient.**
5. **Invoke the request to the Microsoft Graph API.**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Register the application with the Microsoft identity platform**
Before any code can retrieve a token or talk to Graph, the application must exist in Azure AD (Entra ID). This registration generates the Application (Client) ID and Tenant ID necessary for configuration.

**2. Build a client by using the client app ID**
This step refers to configuring the MSAL (Microsoft Authentication Library) client application (e.g., `ConfidentialClientApplicationBuilder` or `PublicClientApplicationBuilder`) using the IDs obtained in step 1. This "client" handles the low-level OAuth token acquisition.

**3. Create an authentication provider**
The Microsoft Graph SDK relies on an `IAuthenticationProvider` to inject the access token into HTTP requests. This provider wraps the MSAL client created in step 2 (often using classes like `ClientCredentialProvider` or `AuthorizationCodeProvider`).

**4. Create a new instance of the GraphServiceClient**
Once you have the authentication provider, you instantiate the `GraphServiceClient`. This is the main entry point for the SDK, and it requires the auth provider as a constructor argument to ensure all outgoing requests are authenticated.

**5. Invoke the request to the Microsoft Graph API**
Finally, with the initialized `GraphServiceClient`, you can write the code to fetch the data, such as `await graphClient.Me.Request().GetAsync();`.

**References:**
*   [Get started with Microsoft Graph SDK](https://learn.microsoft.com/en-us/graph/sdks/create-client?tabs=csharp)
*   [Register an application with the Microsoft identity platform](https://learn.microsoft.com/en-us/entra/identity-platform/quickstart-register-app)

--------------------------------------------------------------------------------
üìå Question 78
--------------------------------------------------------------------------------
You develop and add several functions to an Azure Function app that uses the latest runtime host. The functions contain several REST API endpoints secured by using SSL. The Azure Function app runs in a Consumption plan.

You must send an alert when any of the function endpoints are unavailable or responding too slowly.

You need to monitor the availability and responsiveness of the functions.

What should you do?

- A. Create a URL ping test.
- B. Create a timer triggered function that calls TrackAvailability() and send the results to Application Insights.
- C. Create a timer triggered function that calls GetMetric("Request Size") and send the results to Application Insights.
- D. Add a new diagnostic setting to the Azure Function app. Enable the FunctionAppLogs and Send to Log Analytics options.

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
**B. Create a timer triggered function that calls TrackAvailability() and send the results to Application Insights.**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**Why option B is correct:**
To monitor availability and responsiveness in a **Consumption plan**, you cannot rely on the standard "URL ping tests" (Availability tests) found in the Azure Portal because the classic ping test agents cannot always reliably wake up or reach Consumption-based functions that might scale to zero or have cold starts affecting the timeout thresholds.

The recommended pattern (and standard workaround for complex or internal availability logic) is to create a specific **Timer Triggered Function** (often called an "Availability Function") that runs inside your infrastructure. This function:
1.  Executes custom logic to call your endpoints (HTTP requests).
2.  Measures the response time.
3.  Uses the Application Insights SDK to call `TrackAvailability()`.

This method bypasses the limitations of the portal-based ping tests, ensures the testing logic runs within your network boundary (if applicable), and provides full control over what defines "slow" or "unavailable."

**Why others are incorrect:**
*   **A. Create a URL ping test:** The classic URL ping test (Standard Availability Test) is generally used for public-facing endpoints. However, on a Consumption plan, these external pings might fail due to cold starts (timeouts) rather than actual unavailability, or they might not authenticate correctly if the function requires complex auth logic not supported by the simple ping configuration. More importantly, Microsoft often steers advanced scenarios toward custom availability tracking via code (Option B) or Standard tests (which are now often deprecated in favor of the newer standard tests that run on Azure Logic App or custom agents, but Option B mimics the custom agent behavior perfectly).
*   **C. GetMetric("Request Size"):** "Request Size" is unrelated to availability (uptime) or responsiveness (latency).
*   **D. Diagnostic settings:** Sending logs to Log Analytics is for retrospective analysis and debugging. It records what happened *after* requests were made by users. it does not *actively* probe the endpoints to generate alerts if traffic stops or if the system is idle.

**References:**
*   [Track availability of any web site (Custom Availability Tests)](https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability-azure-functions)

--------------------------------------------------------------------------------
üìå Question 79 ‚≠ê‚≠ê‚≠ê
--------------------------------------------------------------------------------
You deploy an ASP.NET web app to Azure App Service.
You must monitor the web app by using Application Insights.
You need to configure Application Insights to meet the requirements.

Which feature should you use?

**Requirement: Automatically warn you of potential performance problems and failure anomalies in the web app.**
1. Smart Detection
2. Snapshot Debugger
3. Profiler
4. Multi-step test

**Requirement: Automatically collect the state of the source code and variables when an exception is thrown in the web app.**
1. Smart Detection
2. Snapshot Debugger
3. Profiler
4. Multi-step test

**Requirement: Capture performance traces of the web app without negatively affecting users of the web app.**
1. Smart Detection
2. Snapshot Debugger
3. Profiler
4. Multi-step test

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **Automatically warn you...:** Smart Detection
2. **Automatically collect the state...:** Snapshot Debugger
3. **Capture performance traces...:** Profiler

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. Smart Detection**
**Smart Detection** (formerly Proactive Detection) automatically analyzes the telemetry sent by your application. It uses machine learning to detect anomalies such as a sudden rise in failure rates, abnormal load patterns, or performance degradation (slow server response times). It requires no configuration to start working and sends emails or alerts ("warn you") when issues are detected.

**2. Snapshot Debugger**
The **Snapshot Debugger** monitors exception telemetry. When an exception occurs, it captures a "snapshot" of the production environment's state. This snapshot includes the call stack and the values of local variables at the moment the error happened, allowing developers to debug production issues as if they were running locally.

**3. Profiler**
The **Application Insights Profiler** captures detailed performance traces (flame charts showing exactly how long each line of code or database call took). It is designed to run in production with low impact. It uses a sampling technique (collecting traces only occasionally or during high load) to ensure it does not negatively affect the end-user experience while still gathering deep diagnostic data on slow requests.

**Why Multi-step test is incorrect:**
*   **Multi-step test:** This is a type of Availability Test (Web Test) used to simulate a user sequence (e.g., login, search, checkout) to verify the application remains reachable and functional. It does not inspect internal code state or profit CPU performance.

**References:**
*   [Smart Detection in Application Insights](https://learn.microsoft.com/en-us/azure/azure-monitor/app/proactive-diagnostics)
*   [Debug snapshots on exceptions in .NET apps](https://learn.microsoft.com/en-us/azure/azure-monitor/app/snapshot-debugger)
*   [Profile live Azure App Service apps with Application Insights](https://learn.microsoft.com/en-us/azure/azure-monitor/profiler/profiler)

--------------------------------------------------------------------------------
üìå Question 80  ‚≠ê‚≠ê‚≠ê
--------------------------------------------------------------------------------
You develop and deploy an Azure App Service web app to a production environment. You enable the Always On setting and the Application Insights site extensions.

You deploy a code update and receive multiple failed requests and exceptions in the web app.

You need to validate the performance and failure counts of the web app in near real time.

Which Application Insights tool should you use?

A. Profiler
B. Smart Detection
C. Live Metrics Stream
D. Application Map
E. Snapshot Debugger

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
**C. Live Metrics Stream**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**C. Live Metrics Stream**
The key phrase in the requirement is **"near real time"**. Live Metrics Stream (also known as "Live Stream") is the only tool in the Application Insights suite that provides a streaming view (typically with less than 1 second latency) of the health of your application. It displays live charts for Request Rate, Failure Rate, Exception Rate, and CPU usage instantly. This is the standard tool used by DevOps teams to "watch" the health of an application immediately after a deployment.

**Why others are incorrect:**
*   **A. Profiler:** Collects detailed performance traces for individual requests to identify code bottlenecks. It is not an aggregated dashboard for real-time traffic monitoring.
*   **B. Smart Detection:** An automated system that uses machine learning to detect anomalies over time and sends alerts (e.g., email). It is not a real-time visualization dashboard.
*   **D. Application Map:** Shows the topology and dependency health (e.g., links between web app and database). While it updates frequently, it is based on aggregated telemetry which has a slight ingestion latency (minutes), unlike the sub-second stream of Live Metrics.
*   **E. Snapshot Debugger:** Captures the state of source code and variables when an exception is thrown. It is a debugging tool for post-mortem analysis, not a monitoring dashboard for real-time performance and failure counts.

**References:**
*   [Live Metrics Stream: Monitor & Diagnose with 1-second latency](https://learn.microsoft.com/en-us/azure/azure-monitor/app/live-stream)
