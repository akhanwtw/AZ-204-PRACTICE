--------------------------------------------------------------------------------
üìå Question 81
--------------------------------------------------------------------------------
You are developing applications for a company. You plan to host the applications on Azure App Services.

The company has the following requirements:
*   Every five minutes verify that the websites are responsive.
*   Verify that the websites respond within a specified time threshold. Dependent requests such as images and JavaScript files must load properly.
*   Generate alerts if a website is experiencing issues.
*   If a website fails to load, the system must attempt to reload the site three more times.

You need to implement this process with the least amount of effort.

What should you do?

- A. Create a Selenium web test and configure it to run from your workstation as a scheduled task.
- B. Set up a URL ping test to query the home page.
- C. Create an Azure function to query the home page.
- D. Create a multi-step web test to query the home page.
- E. Create a Custom Track Availability Test to query the home page.

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
**B. Set up a URL ping test to query the home page.**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**B. Set up a URL ping test to query the home page.**
This option meets all requirements with the **least amount of effort**:
1.  **Responsiveness & Threshold**: You can configure the test frequency (e.g., 5 minutes) and set a specific Timeout threshold in the portal configuration.
2.  **Dependent Requests**: The "URL ping test" (specifically the configuration in Application Insights availability tests, often called "Standard" or "Classic") includes a checkbox option labeled **"Parse dependent requests"**. Enabling this prompts the test agent to request images, scripts, and style files, ensuring they load properly.
3.  **Retry logic**: Azure Application Insights availability agents have built-in logic to handle transient failures. If a test fails from a specific location, the agent automatically retries the test (typically attempting confirmation retries) before reporting it as a failure to minimize false positives. This satisfies the "reload... three more times" requirement without custom coding.
4.  **Least Effort**: This is a configuration-only solution available directly in the Azure Portal, requiring no code (Azure Function), no external tools (Selenium), and no recording steps (Multi-step).

**Why others are incorrect:**
*   **A. Selenium web test:** Requires significant effort to set up and maintain a scheduled task on a local workstation (which is also not a robust cloud solution).
*   **C. Azure function:** Requires writing custom code to handle HTTP requests, dependency parsing, retry loops, and alerting. This is high effort.
*   **D. Multi-step web test:** While this *could* work, it requires using Visual Studio to record a `.webtest` file and upload it. Since the requirement is only to query the *home page*, a multi-step sequence is unnecessary overhead compared to a single URL test. Additionally, Multi-step web tests are deprecated in favor of custom tests for advanced scenarios.
*   **E. Custom Track Availability Test:** Requires writing a script (e.g., C# or JavaScript) to manually call `TrackAvailability`. This provides maximum control but is high effort compared to the out-of-the-box configuration of Option B.

**References:**
*   [Monitor the availability of any website (URL Ping / Standard tests)](https://learn.microsoft.com/en-us/azure/azure-monitor/app/monitor-web-app-availability)

--------------------------------------------------------------------------------
üìå Question 82
--------------------------------------------------------------------------------
A web service provides customer summary information for e-commerce partners. The web service is implemented as an Azure Function app with an HTTP trigger.

Access to the API is provided by an Azure API Management instance (Consumption plan). All API calls are authenticated by using OAuth.

API calls must be cached. Customers must not be able to view cached data for other customers.

You need to configure API Management policies for caching.

How should you complete the policy statement?

**caching-type**
1. Internal
2. External
...

**downstream-caching-type**
1. Public
2. Private
...

**vary-by-header**
1. Authorization
2. Expect
...

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **caching-type:** Internal
2. **downstream-caching-type:** Private
3. **vary-by-header:** Authorization

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. caching-type: Internal**
The `<cache-lookup>` policy attribute `caching-type` defines where the cache is stored. **Internal** refers to the built-in API Management cache. While the Consumption tier technically requires an external Redis cache for persistence, in the context of policy syntax questions, "Internal" is the standard value to denote local gateway caching operations versus "External".

**2. downstream-caching-type: Private**
The `downstream-caching-type` attribute controls the `Cache-Control` header sent to the client.
*   **Private:** Sets `Cache-Control: private`. This ensures that the response is cached only by the client's browser and **not** by shared intermediate proxies or CDNs. This is critical for the requirement "Customers must not be able to view cached data for other customers."
*   **Public:** Would allow shared proxies to cache the response, potentially serving User A's data to User B.

**3. vary-by-header: Authorization**
To ensure that "Customers must not be able to view cached data for other customers," the server-side cache must treat requests from different users as unique. Since the API uses **OAuth**, the user's identity is contained in the **Authorization** header (the Bearer token). Adding `<vary-by-header>Authorization</vary-by-header>` forces the cache to store a separate copy of the response for every unique auth token.

**References:**
*   [API Management caching policies (cache-lookup)](https://learn.microsoft.com/en-us/azure/api-management/api-management-caching-policies#CacheLookup)

--------------------------------------------------------------------------------
üìå Question 83 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
--------------------------------------------------------------------------------
A web service provides customer summary information for e-commerce partners. The web service is implemented as an Azure Function app with an HTTP trigger.

Access to the API is provided by an Azure API Management instance (Consumption plan). All API calls are authenticated by using OAuth.

API calls must be cached. Customers must not be able to view cached data for other customers.

You need to configure API Management policies for caching.

How should you complete the policy statement?

**caching-type**
1. Internal
2. External
...

**downstream-caching-type**
1. Public
2. Private
...

**vary-by-header**
1. Authorization
2. Expect
...

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **caching-type:** Internal
2. **downstream-caching-type:** Private
3. **vary-by-header:** Authorization

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. caching-type: Internal**
The `<cache-lookup>` policy attribute `caching-type` defines where the cache is stored. **Internal** refers to the built-in API Management cache. While the Consumption tier technically requires an external Redis cache for persistence, in the context of policy syntax questions, "Internal" is the standard value to denote local gateway caching operations versus "External".

**2. downstream-caching-type: Private**
The `downstream-caching-type` attribute controls the `Cache-Control` header sent to the client.
*   **Private:** Sets `Cache-Control: private`. This ensures that the response is cached only by the client's browser and **not** by shared intermediate proxies or CDNs. This is critical for the requirement "Customers must not be able to view cached data for other customers."
*   **Public:** Would allow shared proxies to cache the response, potentially serving User A's data to User B.

**3. vary-by-header: Authorization**
To ensure that "Customers must not be able to view cached data for other customers," the server-side cache must treat requests from different users as unique. Since the API uses **OAuth**, the user's identity is contained in the **Authorization** header (the Bearer token). Adding `<vary-by-header>Authorization</vary-by-header>` forces the cache to store a separate copy of the response for every unique auth token.

**References:**
*   [API Management caching policies (cache-lookup)](https://learn.microsoft.com/en-us/azure/api-management/api-management-caching-policies#CacheLookup)

--------------------------------------------------------------------------------
üìå Question 84
--------------------------------------------------------------------------------
An organization hosts web apps in Azure. The organization uses Azure Monitor.

You discover that configuration changes were made to some of the web apps.

You need to identify the configuration changes.

Which Azure Monitor log should you review?

- A. AppServiceAppLogs
- B. AppServiceEnvironmentPlatformlogs
- C. AppServiceConsoleLogs
- D. AppServiceAuditLogs

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
**D. AppServiceAuditLogs**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**D. AppServiceAuditLogs**
To identify "configuration changes" or administrative actions, you must look at auditing data. In the context of the specific log categories available for Azure App Service Resource Logs:
*   **AppServiceAuditLogs** is the category intended to capture audit-related events (such as logins via FTP or Kudu/SCM site, and publishing activities). While the primary source for broad control-plane configuration changes is usually the **Azure Activity Log**, among the choices provided (which are all Resource Log specific tables), `AppServiceAuditLogs` is the only log dedicated to administrative/security auditing rather than application performance.

**Why others are incorrect:**
*   **A. AppServiceAppLogs:** These are runtime logs generated by the application code itself (e.g., traces, exceptions, errors). They show *how* the app is running, not *how* it was configured.
*   **B. AppServiceEnvironmentPlatformlogs:** These logs relate to the health and status of the App Service Environment (ASE) infrastructure (the hosting components), not the specific configuration changes of the web apps running inside it.
*   **C. AppServiceConsoleLogs:** These capture the standard output (stdout) and standard error (stderr) streams from the application container. Like `AppServiceAppLogs`, they are used for debugging application logic errors, not for auditing administrative changes.

**References:**
*   [Enable diagnostics logging for apps in Azure App Service](https://learn.microsoft.com/en-us/azure/app-service/troubleshoot-diagnostic-logs)

--------------------------------------------------------------------------------
üìå Question 85
--------------------------------------------------------------------------------
You develop and deploy an ASP.NET web app to Azure App Service. You use Application Insights telemetry to monitor the app.

You must test the app to ensure that the app is available and responsive from various points around the world and at regular intervals. If the app is not responding, you must send an alert to support staff.

You need to configure a test for the web app.

Which two test types can you use? Each correct answer presents a complete solution.

- A. integration
- B. multi-step web
- C. URL ping
- D. unit
- E. load

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **B. multi-step web**
2. **C. URL ping**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. URL ping (C)**
This is the standard **Availability Test** (often referred to as a "ping test" or "Standard test") in Application Insights. It allows you to configure a specific URL to be validated from **multiple global locations** at **regular intervals** (e.g., every 5 minutes). It measures response time (responsiveness) and success status (availability). If the endpoint fails or times out, an alert is triggered.

**2. multi-step web (B)**
This test type allows you to simulate a sequence of user actions (e.g., logging in, searching, adding to cart) rather than just pinging a single URL. Like the URL ping test, it runs from **various global points** at **regular intervals** to ensure key user flows are functional.
*(Note: While the classic Visual Studio .webtest format is deprecated in favor of custom tests, "Multi-step web test" remains the terminology for complex availability scenarios in this exam context).*

**Why others are incorrect:**
*   **A. integration:** Integration tests are typically run during the build/deployment pipeline (CI/CD) to verify component interaction, not continuously from global locations for production monitoring.
*   **D. unit:** Unit tests validate individual code units in isolation during development or build, not production availability.
*   **E. load:** Load tests are used to determine how the system behaves under high volume of traffic. While they measure responsiveness, they are typically run as discrete performance validation events, not as continuous 24/7 availability monitors for alerting purposes.

**References:**
*   [Monitor the availability of any website](https://learn.microsoft.com/en-us/azure/azure-monitor/app/monitor-web-app-availability)

--------------------------------------------------------------------------------
üìå Question 86 
--------------------------------------------------------------------------------
Case study -

This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.

To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.

At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.

To start the case study -

To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. When you are ready to answer a question, click the Question button to return to the question.

Background -

VanArsdel, Ltd. is a global office supply company. The company is based in Canada and has retail store locations across the world. The company is developing several cloud-based solutions to support their stores, distributors, suppliers, and delivery services.

Current environment -

Corporate website -

The company provides a public website located at http://www.vanarsdelltd.com. The website consists of a React JavaScript user interface, HTML, CSS, image assets, and several APIs hosted in Azure Functions.

Retail Store Locations -

The company supports thousands of store locations globally. Store locations send data every hour to an Azure Blob storage account to support inventory, purchasing and delivery services. Each record includes a location identifier and sales transaction information.

Requirements -

The application components must meet the following requirements:

Corporate website -

‚Ä¢ Secure the website by using SSL.

‚Ä¢ Minimize costs for data storage and hosting.

‚Ä¢ Implement native GitHub workflows for continuous integration and continuous deployment (CI/CD).

‚Ä¢ Distribute the website content globally for local use.

‚Ä¢ Implement monitoring by using Application Insights and availability web tests including SSL certificate validity and custom header value verification.

‚Ä¢ The website must have 99.95 percent uptime.

Retail store locations -

‚Ä¢ Azure Functions must process data immediately when data is uploaded to Blob storage. Azure Functions must update Azure Cosmos DB by using native SQL language queries.

‚Ä¢ Audit store sale transaction information nightly to validate data, process sales financials, and reconcile inventory.

Delivery services -

‚Ä¢ Store service telemetry data in Azure Cosmos DB by using an Azure Function. Data must include an item id, the delivery vehicle license plate, vehicle package capacity, and current vehicle location coordinates.

‚Ä¢ Store delivery driver profile information in Azure Active Directory (Azure AD) by using an Azure Function called from the corporate website.

Inventory services -

The company has contracted a third-party to develop an API for inventory processing that requires access to a specific blob within the retail store storage account for three months to include read-only access to the data.

Security -

‚Ä¢ All Azure Functions must centralize management and distribution of configuration data for different environments and geographies, encrypted by using a company-provided RSA-HSM key.

‚Ä¢ Authentication and authorization must use Azure AD and services must use managed identities where possible.

Issues -

Retail Store Locations -

‚Ä¢ You must perform a point-in-time restoration of the retail store location data due to an unexpected and accidental deletion of data.

‚Ä¢ Azure Cosmos DB queries from the Azure Function exhibit high Request Unit (RU) usage and contain multiple, complex queries that exhibit high point read latency for large items as the function app is scaling.

**Corporate website**
*   Public website: `http://www.vanarsdelltd.com`
*   Stack: React JavaScript UI, HTML, CSS, Azure Functions APIs.
*   **Requirement:** "Implement monitoring by using Application Insights and availability web tests including **SSL certificate validity** and **custom header value verification**."

You need to test the availability of the corporate website based on the requirements.
Which two test types can you use? Each correct answer presents a complete solution.

A. Standard
B. URL ping
C. Custom testing using the TrackAvailability API method
D. Multi-step

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
1. **A. Standard**
2. **C. Custom testing using the TrackAvailability API method**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. A. Standard (Standard Availability Test)**
The **Standard** test is the modern version of the single-URL availability monitor in Azure Application Insights. It specifically includes a configuration option to **"Enable SSL certificate validity"** checks, which proactively alerts you on certificate lifetime expiration and authority validity. This directly addresses the "SSL certificate validity" requirement in the case study. While its UI is limited for complex logic, it is the primary configuration-based tool for this specific requirement.

**2. C. Custom testing using the TrackAvailability API method**
**Custom testing** involves writing code (e.g., in an Azure Function) that runs validation logic and sends the results to Application Insights using the `TrackAvailability()` method. This approach provides a "complete solution" because it offers infinite flexibility: you can write code to programmatically verify specific **SSL properties** (validity, chain, expiry date) *and* strictly validate **custom header values** in the HTTP response, which might be difficult or impossible to configure in the portal-based "Standard" test UI. This is the recommended pattern for complex validation scenarios.

**Why others are incorrect/less suitable:**
*   **B. URL ping:** This is the legacy "Classic" version of the single-URL test. It checks for a 200 OK status but lacks the dedicated "Proactive SSL certificate validity" features found in the Standard test (it doesn't warn you 30 days before expiration, for example). It is deprecated in favor of **Standard**.
*   **D. Multi-step:** This refers to the legacy "Classic" multi-step web tests (using Visual Studio .webtest files). While it *can* perform header validation and check SSL connections, it is **deprecated** functionality. Microsoft recommends moving complex logic to **Custom** tests (Option C). Furthermore, the specific "SSL certificate validity" monitoring feature is a selling point of the Standard test, not the classic runner.

**References:**
*   [Standard availability tests (Preview became Standard)](https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability-standard-tests)
*   [Custom availability tests (TrackAvailability)](https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability-azure-functions)
*   [Availability tests in Application Insights overview](https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability-overview)

--------------------------------------------------------------------------------
üìå Question 87
--------------------------------------------------------------------------------
You are developing several microservices to run on Azure Container Apps.

You need to monitor and diagnose the microservices.

Which features should you use? To answer, select the appropriate feature in the answer area.

**Requirement 1:** View console logs from a container in near real-time.
1. Log streaming
2. Container console
3. Azure Monitor metrics
4. Azure Monitor Log Analytics

**Requirement 2:** Debug the microservice from inside the container.
1. Container console
2. Azure Monitor metrics
3. Azure Container Registry
4. Azure Monitor Log Analytics

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
**1. View console logs in near real-time:** Log streaming
**2. Debug from inside the container:** Container console

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
**1. View console logs in near real-time (Log streaming)**
Azure Container Apps provides a **Log streaming** feature that allows you to view standard output (stdout) and standard error (stderr) messages from your container as they happen. This is specifically designed for "near real-time" monitoring of application logs without the latency associated with log aggregation services.

**Why others are incorrect:**
*   **Azure Monitor Log Analytics:** While this is the primary storage for long-term retention and querying, there is a distinct ingestion latency (typically a few minutes) between when a log is generated and when it appears in queries. It is not "near real-time" in same sense as a live stream.
*   **Container console:** This connects you to a shell inside the container but does not inherently aggregate or stream the application's stdout/stderr logs unless you manually hunt for log files on the disk (which may not exist if logs go to stdout).
*   **Azure Monitor metrics:** This handles numerical data (CPU, Memory, Request counts), not text logs.

**2. Debug from inside the container (Container console)**
To "debug... from inside the container" usually implies needing interactive access to the file system, network tools, or process list within the running environment. The **Container console** feature in Azure Container Apps allows you to launch an interactive shell (e.g., `/bin/sh` or `/bin/bash`) directly into a replica of your container. This lets you run commands like `ls`, `curl`, or `top` to diagnose issues.

**Why others are incorrect:**
*   **Azure Monitor metrics / Log Analytics:** These are observational tools that work from the "outside." You cannot execute commands or explore the live filesystem with them.
*   **Azure Container Registry:** This is a storage service for container images, not a runtime diagnostic tool for running containers.

**References:**
*   [Log streaming in Azure Container Apps](https://learn.microsoft.com/en-us/azure/container-apps/log-streaming)
*   [Connect to a console in Azure Container Apps](https://learn.microsoft.com/en-us/azure/container-apps/console-connect)


--------------------------------------------------------------------------------
üìå Question 88
--------------------------------------------------------------------------------
You are developing an Azure App Service web app.

The web app must securely store session information in Azure Redis Cache.

You need to connect the web app to Azure Redis Cache.

Which three Azure Redis Cache properties should you use? Each correct answer presents part of the solution.

NOTE: Each correct selection is worth one point.

- A. Access key
- B. SSL port
- C. Subscription name
- D. Location
- E. Host name
- F. Subscription id

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
**A. Access key**
**B. SSL port**
**E. Host name**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
To connect an application to Azure Redis Cache, you typically need to construct a connection string or configure a Redis client. The three essential components required for a secure connection are:

1.  **Host name (E):** This is the public DNS endpoint of your cache instance (e.g., `your-cache-name.redis.cache.windows.net`). It tells the client where to send the traffic.
2.  **SSL port (B):** The question specifies the need to **securely** store session information. By default, Azure Redis Cache provides an SSL port (usually `6380`) for encrypted traffic. Using the non-SSL port (`6379`) is disabled by default for new caches and is not recommended for secure communications.
3.  **Access key (A):** This acts as the password for the Redis server. Azure provides a Primary and a Secondary key; either is required to authenticate the connection.

**Why others are incorrect:**
*   **Subscription name, Subscription ID, Location:** These are Azure resource management properties used for billing and organizing resources within the Azure Portal or ARM templates. They are not part of the Redis protocol and are not used by the Redis client to establish a data connection.

**Reference Connection String Example:**
`mycache.redis.cache.windows.net:6380,password=YOUR_ACCESS_KEY,ssl=True,abortConnect=False`

--------------------------------------------------------------------------------
üìå Question 89
--------------------------------------------------------------------------------
You are building an application to track cell towers that are available to phones in near real time. A phone will send information to the application by using the Azure Web PubSub service. The data will be processed by using an Azure Functions app. Traffic will be transmitted by using a content delivery network (CDN).

The Azure function must be protected against misconfigured or unauthorized invocations.

You need to ensure that the CDN allows for the Azure function protection.

Which HTTP header should be on the allowed list?

- A. Authorization
- B. WebHook-Request-Callback
- C. Resource
- D. WebHook-Request-Origin

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
**D. WebHook-Request-Origin**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
Azure Web PubSub uses the **CloudEvents** specification to deliver events to upstream event handlers (like Azure Functions). As part of this specification, an **Abuse Protection** handshake is required to ensure that the event handler explicitly permits the Web PubSub service to send events to it.

**Why `WebHook-Request-Origin` is the correct answer:**
1.  **Validation Handshake:** When the Web PubSub service attempts to register or validate an event handler, it likely sends an HTTP `OPTIONS` request. This request includes the **`WebHook-Request-Origin`** header essentially asking, "I am this service; do you accept events from me?"
2.  **Protection Mechanism:** This prevents "misconfigured or unauthorized invocations" by ensuring that the Function App is not bombarded by random traffic claiming to be events. The Function App (or the Web PubSub trigger binding) checks this header and responds with `WebHook-Allowed-Origin`.
3.  **CDN Configuration:** If a CDN sits between the Web PubSub service and the Azure Function, it typically filters headers to improve caching and security. If the CDN strips the `WebHook-Request-Origin` header, the Function App cannot validate the handshake request, and the integration will fail. Therefore, this specific header must be whitelisted/allowed on the CDN.

**Why others are incorrect:**
*   **Authorization:** While used for standard authentication (Bearer keys, API tokens), the specific handshake mechanism for CloudEvents/Web PubSub abuse protection relies on the Origin header pattern.
*   **WebHook-Request-Callback:** This is not part of the standard CloudEvents abuse protection headers for Azure Web PubSub.
*   **Resource:** This is not a standard HTTP header used for this validation handshake.

**References:**
*   [CloudEvents Web Hooks for Event Delivery - Abuse Protection](https://github.com/cloudevents/spec/blob/v1.0/http-webhook.md#4-abuse-protection)
*   [Azure Web PubSub CloudEvents Integration](https://learn.microsoft.com/en-us/azure/azure-web-pubsub/reference-cloud-events#cloud-events-abuse-protection)

--------------------------------------------------------------------------------
üìå Question 90
--------------------------------------------------------------------------------
You develop and deploy a web app to Azure App Service. The Azure App Service uses a Basic plan in a single region.

Users report that the web app is responding slow. You must capture the complete call stack to help identify performance issues in the code. Call stack data must be correlated across app instances. You must minimize cost and impact to users on the web app.

You need to capture the telemetry.

Which three actions should you perform? Each correct answer presents part of the solution.

NOTE: Each correct selection is worth one point.

- A. Restart all apps in the App Service plan.
- B. Enable Application Insights site extensions.
- C. Upgrade the Azure App Service plan to Premium.
- D. Enable Profiler.
- E. Enable the Always On setting for the app service.
- F. Enable Snapshot debugger.
- G. Enable remote debugging.

--------------------------------------------------------------------------------
‚úÖ Correct Answer
--------------------------------------------------------------------------------
- **B. Enable Application Insights site extensions.**
- **D. Enable Profiler.**
- **E. Enable the Always On setting for the app service.**

--------------------------------------------------------------------------------
üìù Explanation
--------------------------------------------------------------------------------
To diagnose a "slow responding" web app while minimizing cost and impact on a Basic plan, you should use the **Application Insights Profiler**.

1.  **Enable Profiler (D):** The Profiler is the specific tool designed to identify performance "hot paths" in your code. It automatically captures detailed traces and the complete call stack for requests that take longer than usual, allowing you to see exactly which methods are causing the slowdown.
2.  **Enable Application Insights site extensions (B):** To run the Profiler on Azure App Service without modifying your codebase (codeless attach), you must enable the Application Insights instrumentation (site extension) on the App Service. This provides the necessary integration for collecting telemetry and running the profiling agent.
3.  **Enable the Always On setting (E):** The Profiler (and the telemetry agent) runs as a background process (WebJob). In the Basic tier, web apps can unload if they are idle. Enabling "Always On" ensures the app and its monitoring tools remain running continuously to capture traces when issues occur. "Always On" is included in the Basic tier.

**Why others are incorrect:**
*   **C. Upgrade to Premium:** The Profiler is supported on the **Basic** tier and higher. Upgrading to Premium would significantly increase costs without being necessary for this specific feature.
*   **F. Enable Snapshot debugger:** Snapshot Debugger is primarily used for investigating **exceptions** (crashes/errors), not general slowness. Furthermore, Snapshot Debugger typically requires the **Standard** tier or higher, which would violate the "minimize cost" requirement.
*   **G. Enable remote debugging:** This is a manual, high-impact intervention (it can pause execution) suitable for development, not for gathering telemetry across instances in a live environment.
*   **A. Restart:** This temporarily clears symptoms but does not "capture the call stack" or solve the root cause of the code performance issue.
